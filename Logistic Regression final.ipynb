{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc6e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "def data_loader(df):\n",
    "    import numpy as np # importing Numpy; Python library \n",
    "    import pandas as pd # Importing Pandas to \n",
    "    # reading csv file\n",
    "    df = pd.read_csv(\"creditcard.csv\") \n",
    "    # drop Time Column from the dataset\n",
    "    df.drop('Time', inplace=True, axis=1)\n",
    "    #return data(csv) file\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b12db5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_loader(\"creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "407279ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024107</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>0.052485</td>\n",
       "      <td>0.081667</td>\n",
       "      <td>-0.002974</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.023327</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000526</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>-0.053766</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021129</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>-0.016379</td>\n",
       "      <td>-0.006791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006482</td>\n",
       "      <td>-0.058416</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>-0.074129</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024081</td>\n",
       "      <td>-0.018430</td>\n",
       "      <td>0.036693</td>\n",
       "      <td>0.022505</td>\n",
       "      <td>-0.004424</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>-0.097124</td>\n",
       "      <td>0.008445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007120</td>\n",
       "      <td>0.070582</td>\n",
       "      <td>0.020296</td>\n",
       "      <td>-0.150349</td>\n",
       "      <td>-0.031824</td>\n",
       "      <td>-0.039546</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.001765</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017130</td>\n",
       "      <td>-0.002547</td>\n",
       "      <td>0.037102</td>\n",
       "      <td>-0.051157</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.017015</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>-0.088940</td>\n",
       "      <td>-0.002235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003109</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>-0.256421</td>\n",
       "      <td>0.062880</td>\n",
       "      <td>-0.063096</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.020533</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.032048</td>\n",
       "      <td>0.023883</td>\n",
       "      <td>-0.003580</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>-0.003695</td>\n",
       "      <td>0.052436</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>0.073015</td>\n",
       "      <td>-0.003068</td>\n",
       "      <td>0.030814</td>\n",
       "      <td>-0.020010</td>\n",
       "      <td>0.142804</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.024107 -0.001001  0.052485  0.081667 -0.002974  0.006308  0.001987   \n",
       "1  0.021129  0.003660  0.003445  0.026557  0.000528 -0.001124 -0.000653   \n",
       "2 -0.024081 -0.018430  0.036693  0.022505 -0.004424  0.024563  0.006563   \n",
       "3 -0.017130 -0.002547  0.037102 -0.051157 -0.000091  0.017015  0.001970   \n",
       "4 -0.020533  0.012071  0.032048  0.023883 -0.003580  0.001309  0.004917   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.001348  0.023327  0.003693  ... -0.000526  0.025412 -0.002466  0.014599   \n",
       "1  0.001162 -0.016379 -0.006791  ... -0.006482 -0.058416  0.002261 -0.074129   \n",
       "2  0.003383 -0.097124  0.008445  ...  0.007120  0.070582  0.020296 -0.150349   \n",
       "3  0.005155 -0.088940 -0.002235  ... -0.003109  0.000482 -0.004247 -0.256421   \n",
       "4 -0.003695  0.052436  0.030627  ... -0.000271  0.073015 -0.003068  0.030814   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.012485 -0.053766  0.004225 -0.000622  0.005824    0.0  \n",
       "1  0.016237  0.035792 -0.000284  0.000435  0.000105    0.0  \n",
       "2 -0.031824 -0.039546 -0.001751 -0.001765  0.014739    0.0  \n",
       "3  0.062880 -0.063096  0.001984  0.001816  0.004807    0.0  \n",
       "4 -0.020010  0.142804  0.006941  0.006356  0.002724    0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_processing(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column]  / df[column].abs().max()       \n",
    "    return df\n",
    "data = pre_processing(data)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01dad83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (170883, 29)\n",
      "y_train shape: (170883,)\n",
      "X_test shape: (56962, 29)\n",
      "y_test shape: (56962,)\n",
      "X_val shape: (56962, 29)\n",
      "y val shape: (56962,)\n"
     ]
    }
   ],
   "source": [
    "X=data.iloc[:,:-1].values\n",
    "y=data.iloc[:,-1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, shuffle = True, random_state = 8)\n",
    "# Use the same function above for the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "print(\"X_val shape: {}\".format(X_val.shape))\n",
    "print(\"y val shape: {}\".format(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0cb4353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.9990168884519505\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dp/0dddlf7j5kx8_cy9js6q9pnr0000gn/T/ipykernel_1193/2058856073.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \"\"\"\n\u001b[0;32m-> 1071\u001b[0;31m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[1;32m   1072\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \"\"\"\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1196\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1465\u001b[0m                                     pos_label)\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1275\u001b[0m                          str(average_options))\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty = \"l2\")\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "#predictions = model.predict(X_val)\n",
    "print(predictions )\n",
    "score = model.score(X_val, y_val)\n",
    "print(score)\n",
    "from sklearn.metrics import f1_score\n",
    "f1= f1_score(X_test, predictions)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0b152e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56846     9]\n",
      " [   47    60]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_val, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6385812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 29)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co = model.coef_\n",
    "co.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "515ad9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np \n",
    "from numpy import log,dot,exp,shape\n",
    "import matplotlib.pyplot as plt\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4a380e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(df):\n",
    "    import numpy as np # importing Numpy; Python library \n",
    "    import pandas as pd # Importing Pandas to \n",
    "    # reading csv file\n",
    "    df = pd.read_csv(\"creditcard.csv\") \n",
    "    # drop Time Column from the dataset\n",
    "    df.drop('Time', inplace=True, axis=1)\n",
    "    #return data(csv) file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "636ba63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_loader(\"creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36a650d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024107</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>0.052485</td>\n",
       "      <td>0.081667</td>\n",
       "      <td>-0.002974</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.023327</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000526</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>-0.053766</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021129</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>-0.016379</td>\n",
       "      <td>-0.006791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006482</td>\n",
       "      <td>-0.058416</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>-0.074129</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024081</td>\n",
       "      <td>-0.018430</td>\n",
       "      <td>0.036693</td>\n",
       "      <td>0.022505</td>\n",
       "      <td>-0.004424</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>-0.097124</td>\n",
       "      <td>0.008445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007120</td>\n",
       "      <td>0.070582</td>\n",
       "      <td>0.020296</td>\n",
       "      <td>-0.150349</td>\n",
       "      <td>-0.031824</td>\n",
       "      <td>-0.039546</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.001765</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017130</td>\n",
       "      <td>-0.002547</td>\n",
       "      <td>0.037102</td>\n",
       "      <td>-0.051157</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.017015</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>-0.088940</td>\n",
       "      <td>-0.002235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003109</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>-0.256421</td>\n",
       "      <td>0.062880</td>\n",
       "      <td>-0.063096</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.020533</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.032048</td>\n",
       "      <td>0.023883</td>\n",
       "      <td>-0.003580</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>-0.003695</td>\n",
       "      <td>0.052436</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>0.073015</td>\n",
       "      <td>-0.003068</td>\n",
       "      <td>0.030814</td>\n",
       "      <td>-0.020010</td>\n",
       "      <td>0.142804</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.024107 -0.001001  0.052485  0.081667 -0.002974  0.006308  0.001987   \n",
       "1  0.021129  0.003660  0.003445  0.026557  0.000528 -0.001124 -0.000653   \n",
       "2 -0.024081 -0.018430  0.036693  0.022505 -0.004424  0.024563  0.006563   \n",
       "3 -0.017130 -0.002547  0.037102 -0.051157 -0.000091  0.017015  0.001970   \n",
       "4 -0.020533  0.012071  0.032048  0.023883 -0.003580  0.001309  0.004917   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.001348  0.023327  0.003693  ... -0.000526  0.025412 -0.002466  0.014599   \n",
       "1  0.001162 -0.016379 -0.006791  ... -0.006482 -0.058416  0.002261 -0.074129   \n",
       "2  0.003383 -0.097124  0.008445  ...  0.007120  0.070582  0.020296 -0.150349   \n",
       "3  0.005155 -0.088940 -0.002235  ... -0.003109  0.000482 -0.004247 -0.256421   \n",
       "4 -0.003695  0.052436  0.030627  ... -0.000271  0.073015 -0.003068  0.030814   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.012485 -0.053766  0.004225 -0.000622  0.005824    0.0  \n",
       "1  0.016237  0.035792 -0.000284  0.000435  0.000105    0.0  \n",
       "2 -0.031824 -0.039546 -0.001751 -0.001765  0.014739    0.0  \n",
       "3  0.062880 -0.063096  0.001984  0.001816  0.004807    0.0  \n",
       "4 -0.020010  0.142804  0.006941  0.006356  0.002724    0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_processing(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column]  / df[column].abs().max()       \n",
    "    return df\n",
    "data = pre_processing(data)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c128ad8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9002555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (170883, 29)\n",
      "y_train shape: (170883,)\n",
      "X_test shape: (56962, 29)\n",
      "y_test shape: (56962,)\n",
      "X_val shape: (56962, 29)\n",
      "y val shape: (56962,)\n"
     ]
    }
   ],
   "source": [
    "X=data.iloc[:,:-1].values\n",
    "y=data.iloc[:,-1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, shuffle = True, random_state = 8)\n",
    "# Use the same function above for the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "print(\"X_val shape: {}\".format(X_val.shape))\n",
    "print(\"y val shape: {}\".format(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b01ad81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(self,X):\n",
    "    weights = np.zeros((shape(X)[1]+1,1))\n",
    "    #print(weights)\n",
    "    X = np.c_[np.ones((shape(X)[0],1)),X]\n",
    "    #print(X)\n",
    "    return weights,X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "efcc2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    return the sigmoid of z\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1/ (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "49ce017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights,X = initialize(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa252a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionReg(weights, X_train, Y_train ,Lambda):\n",
    "    \"\"\"\n",
    "    Take in numpy array of theta, X, and y to return the regularize cost function and gradient\n",
    "    of a logistic regression\n",
    "    \"\"\"\n",
    "    \n",
    "    m=len(y_train)\n",
    "    print(m)\n",
    "    y = y_train[:,np.newaxis]\n",
    "    #y = y_train\n",
    "    #print(y)\n",
    "    predictions = sigmoid(X @ weights)\n",
    "    error = (-y * np.log(predictions)) - ((1-y)*np.log(1-predictions))\n",
    "    cost = 1/m * sum(error)\n",
    "    regCost= cost + Lambda/(2*m) * sum(weights**2)\n",
    "    \n",
    "    # compute gradient\n",
    "    j_0= 1/m * (X.transpose() @ (predictions - y))[0]\n",
    "    j_1 = 1/m * (X.transpose() @ (predictions - y))[1:] + (Lambda/m)* weights[1:]\n",
    "    grad= np.vstack((j_0[:,np.newaxis],j_1))\n",
    "    return cost[0], grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "711ff3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170883\n",
      "0.6931471805585467\n"
     ]
    }
   ],
   "source": [
    "Lambda = 0.01\n",
    "cost, grad = costFunctionReg(weights, X, y_train, Lambda)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57af06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionReg(theta, X, y ,Lambda):\n",
    "    \"\"\"\n",
    "    Take in numpy array of theta, X, and y to return the regularize cost function and gradient\n",
    "    of a logistic regression\n",
    "    \"\"\"\n",
    "    \n",
    "    m=len(y)\n",
    "    y=y[:,np.newaxis]\n",
    "    predictions = sigmoid(X @ theta)\n",
    "    error = (-y * np.log(predictions)) - ((1-y)*np.log(1-predictions))\n",
    "    cost = 1/m * sum(error)\n",
    "    regCost= cost + Lambda/(2*m) * sum(theta**2)\n",
    "    \n",
    "    # compute gradient\n",
    "    j_0= 1/m * (X.transpose() @ (predictions - y))[0]\n",
    "    j_1 = 1/m * (X.transpose() @ (predictions - y))[1:] + (Lambda/m)* theta[1:]\n",
    "    grad= np.vstack((j_0[:,np.newaxis],j_1))\n",
    "    return cost[0], grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "518c303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(y,y_hat):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1 and y_hat[i] == 1:\n",
    "            tp += 1\n",
    "        elif y[i] == 1 and y_hat[i] == 0:\n",
    "            fn += 1\n",
    "        elif y[i] == 0 and y_hat[i] == 1:\n",
    "            fp += 1\n",
    "        elif y[i] == 0 and y_hat[i] == 0:\n",
    "            tn += 1\n",
    "\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7a471af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogidticRegression(object):\n",
    "    def sigmoid(self,z):\n",
    "        sig = 1/(1+exp(-z))\n",
    "        return sig\n",
    "    def initialize(self,X):\n",
    "        weights = np.zeros((shape(X)[1]+1,1))\n",
    "        X = np.c_[np.ones((shape(X)[0],1)),X]\n",
    "        return weights,X\n",
    "    def fit(self,X,y,alpha=0.001,iter=400):\n",
    "        weights,X = self.initialize(X)\n",
    "        def cost(theta):\n",
    "            z = dot(X,theta)\n",
    "            cost0 = y.T.dot(log(self.sigmoid(z)))\n",
    "            cost1 = (1-y).T.dot(log(1-self.sigmoid(z)))\n",
    "            cost = -((cost1 + cost0))/len(y)\n",
    "            return cost\n",
    "        cost_list = np.zeros(iter,)\n",
    "        for i in range(iter):\n",
    "            weights = weights - alpha*dot(X.T,self.sigmoid(dot(X,weights))-np.reshape(y,(len(y),1)))\n",
    "            cost_list[i] = cost(weights)\n",
    "        self.weights = weights\n",
    "        return cost_list\n",
    "    def predict(self,X):\n",
    "        z = dot(self.initialize(X)[1],self.weights)\n",
    "        lis = []\n",
    "        for i in self.sigmoid(z):\n",
    "            if i>0.5:\n",
    "                lis.append(1)\n",
    "            else:\n",
    "                lis.append(0)\n",
    "        return lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86e3f435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4fef9e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40243902439024387\n",
      "0.3687150837988827\n"
     ]
    }
   ],
   "source": [
    "obj1 = LogidticRegression()\n",
    "model= obj1.fit(X_train,y_train)\n",
    "y_pred = obj1.predict(X_test)\n",
    "y_train1 = obj1.predict(X_train)\n",
    "#Let's see the f1-score for training and testing data\n",
    "f1_score_tr = F1_score(y_train,y_train1)\n",
    "f1_score_te = F1_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "print(f1_score_tr)\n",
    "print(f1_score_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c9c939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56816    45]\n",
      " [   68    33]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002561e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
